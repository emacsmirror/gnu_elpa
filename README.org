#+html: <a href="https://melpa.org/#/truename-cache"><img alt="MELPA" src="https://melpa.org/packages/truename-cache-badge.svg"/></a> <a href="https://stable.melpa.org/#/truename-cache"><img alt="MELPA Stable" src="https://stable.melpa.org/packages/truename-cache-badge.svg"/></a>
* truename-cache

#+begin_quote
[!WARNING]
This is a BETA release!
Breaking changes are possible.
#+end_quote

This Emacs library provides two things:

1. =truename-cache-get=: A caching alternative to =file-truename=.

2. =truename-cache-collect-files-and-attributes=: Basically an alternative to =directory-files-recursively= that pre-populates cache and returns truenames while minimizing calls to =file-truename=.

** Why?

Truenames are useful as a way to de-duplicate file lists and to cross-reference names in one list with names in another list.

But if you write code that just wraps every file name it encounters in =(file-truename FILE)=, it gets slow if you have large lists of file names. It takes 1,000 milliseconds to process 1,000 file names on my machine.

That is unacceptably slow, at least in the use-case where you often scan a list of directories to see if any new files have appeared or any files were modified or deleted.

That's the sort of thing that might be done as part of a user command.  If the command is to be pleasant to use, it must take less than 100 milliseconds so it feels "instant".  And you may be dealing with not 1,000 but 10,000 or even 100,000 files.

** Bonus: Merging lists

The routine =truename-cache-collect-files-and-attributes= can be used to merge multiple file lists and return de-duplicated truenames.

Some example file-lists in Emacs that may overlap a lot:

- Variable =recentf-list=
- Variable =org-agenda-text-search-extra-files=
- Variable =org-id-files=
- Variable =org-id-extra-files=
- Output of =(org-files-list)=
- Output of =(hash-table-values org-id-locations)=

Even if you =append= and =seq-uniq= these lists, a given file may still be represented multiple times under different names.

To merge, pass all your file-lists in the argument =:infer-dirs-from=.  In truth, it doesn't operate directly on any of the files given, it just infers their parent directories and then scans each directory once.  That turns out to be efficient, even if it's likely to pull in more unique files than were mentioned by any name in the input.

** Bonus: Filtering

While you could simply let =truename-cache-collect-files-and-attributes= return a giant file list and filter it afterwards, there are two reasons to do some filtering through the arguments =:relative-file-deny=, =:relative-dir-deny= and/or =:full-dir-deny= (which take lists of regular expressions).

1. They filter early, so you can avoid recursing into directories that you were never gonna keep anyway -- e.g. the contents of =.git/= or =node_modules/=...

   It can easily be the difference between a runtime of 2.00 seconds and 0.02 seconds!

2. If you wanted to apply your filters to relative file names rather than absolute names ([[https://github.com/org-roam/org-roam/pull/2178][example use-case]]), you'd ordinarily have to use =(relative-file-name FILE DIR)= on every file, and that procedure isn't cheap either.

   That's why it provides =:relative-file-deny=, =:relative-dir-deny=.  Another bottleneck dodged.
